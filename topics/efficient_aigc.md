# Efficient AIGC

Below are resources related to efficient AIGC.

## Table of Contents

- [Efficient AIGC](#efficient-aigc)
  - [Table of Contents](#table-of-contents)
  - [Vision](#vision)
  - [Language](#language)
  - [Multimodal](#multimodal)
  - [Links](#links)

## Vision

<details><summary>2024</summary>

- [Mobile Video Diffusion](https://arxiv.org/abs/2412.07583), ArXiv, 2024.12, Qualcomm. | [project](https://qualcomm-ai-research.github.io/mobile-video-diffusion/)
- [TinyFusion: Diffusion Transformers Learned Shallow](https://arxiv.org/abs/2412.01199), ArXiv, 2024.12, NUS. | [code](https://github.com/VainF/TinyFusion)
</details>

## Language


<details><summary>2024</summary>

- [Compact Language Models via Pruning and Knowledge Distillation](https://openreview.net/pdf?id=9U0nLnNMJ7)ï¼Œ NeurIPS, 2024, NVIDIA. | [code](https://github.com/NVlabs/Minitron)
</details>

## Multimodal

<details><summary>2024</summary>

- [Turbo: Informativity-Driven Acceleration Plug-In for Vision-Language Large Models](https://arxiv.org/pdf/2407.11717), ECCV, 2024, Alibaba & SJTU. | [project](https://voide1220.github.io/turbo/), [code](https://voide1220.github.io/turbo/)
- [MADTP: Multimodal Alignment-Guided Dynamic Token Pruning for Accelerating Vision-Language Transformer](https://openaccess.thecvf.com/content/CVPR2024/papers/Cao_MADTP_Multimodal_Alignment-Guided_Dynamic_Token_Pruning_for_Accelerating_Vision-Language_Transformer_CVPR_2024_paper.pdf), CVPR, 2024, Fudan & THU. | [code](https://github.com/double125/MADTP)
</details>

## Links

- [Awesome-Efficient-LLM-Diffusion](https://github.com/htqin/awesome-efficient-aigc)
- [Efficient-Deep-Learning](https://github.com/MingSun-Tse/Efficient-Deep-Learning)
- [MIT-Han-Lab](https://github.com/mit-han-lab)